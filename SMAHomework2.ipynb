{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a060f0-bcea-4818-ad0e-2a14d0cf444c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company class with the highest total withdrawal value is 'Acq.Corp' with $4021.00 million.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "url = \"https://stockanalysis.com/ipos/withdrawn/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "tables = pd.read_html(StringIO(response.text))\n",
    "df = tables[0]\n",
    "\n",
    "def get_company_class(name):\n",
    "    if pd.isna(name):\n",
    "        return \"Other\"\n",
    "    name = str(name).lower()\n",
    "    patterns = [\n",
    "        (\"acquisition corp\", \"Acq.Corp\"),\n",
    "        (\"incorporation\", \"Inc\"),\n",
    "        (\"inc\", \"Inc\"),\n",
    "        (\"group\", \"Group\"),\n",
    "        (\"ltd\", \"Limited\"),\n",
    "        (\"limited\", \"Limited\"),\n",
    "        (\"holdings\", \"Holdings\")\n",
    "    ]\n",
    "    for pattern, class_name in patterns:\n",
    "        if pattern in name:\n",
    "            return class_name\n",
    "    return \"Other\"\n",
    "\n",
    "company_col = 'Company Name'\n",
    "df['Company Class'] = df[company_col].apply(get_company_class)\n",
    "\n",
    "def parse_price_range(price_str):\n",
    "    if pd.isna(price_str) or price_str.strip() == '-':\n",
    "        return None\n",
    "    price_str = price_str.replace('$', '').strip()\n",
    "    if '-' in price_str:\n",
    "        low, high = map(float, price_str.split('-'))\n",
    "        return (low + high) / 2\n",
    "    return float(price_str)\n",
    "\n",
    "df['Avg. Price'] = df['Price Range'].apply(parse_price_range)\n",
    "\n",
    "df['Shares Offered'] = pd.to_numeric(df['Shares Offered'], errors='coerce')\n",
    "\n",
    "df['Withdrawn Value'] = df['Shares Offered'] * df['Avg. Price'] / 1_000_000\n",
    "\n",
    "grouped = df.groupby('Company Class')['Withdrawn Value'].sum().sort_values(ascending=False)\n",
    "\n",
    "top_class = grouped.index[0]\n",
    "top_value = grouped.iloc[0]\n",
    "\n",
    "print(f\"The company class with the highest total withdrawal value is '{top_class}' with ${top_value:.2f} million.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebc2fed-6866-4580-8b99-07e7c3e12bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  75 of 75 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Sharpe Ratio for the 71 stocks: 0.20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "import yfinance as yf\n",
    "\n",
    "url = \"https://stockanalysis.com/ipos/2024/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "tables = pd.read_html(StringIO(response.text))\n",
    "df_ipos = tables[0]\n",
    "\n",
    "df_ipos['IPO Date'] = pd.to_datetime(df_ipos['IPO Date'])\n",
    "df_ipos = df_ipos[df_ipos['IPO Date'] < '2024-06-01']\n",
    "tickers = df_ipos['Symbol'].tolist()\n",
    "if len(tickers) > 75:\n",
    "    df_ipos = df_ipos.sort_values('IPO Date').head(75)\n",
    "    tickers = df_ipos['Symbol'].tolist()\n",
    "\n",
    "def download_stock_data(tickers, start_date='2024-01-01', end_date='2025-06-07'):\n",
    "    data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker', auto_adjust=False)\n",
    "    stocks_df = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        if ticker in data.columns.levels[0]:\n",
    "            ticker_data = data[ticker][['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "            ticker_data['Ticker'] = ticker\n",
    "            ticker_data['Date'] = ticker_data.index\n",
    "            ticker_data['daily_return'] = ticker_data['Close'].pct_change()\n",
    "            ticker_data['growth_252d'] = ticker_data['Close'] / ticker_data['Close'].shift(252)\n",
    "            ticker_data['volatility'] = ticker_data['daily_return'].rolling(window=252).std() * np.sqrt(252)\n",
    "            if len(ticker_data) >= 252 and ticker_data['Close'].count() >= 252:\n",
    "                stocks_df = pd.concat([stocks_df, ticker_data])\n",
    "    return stocks_df\n",
    "\n",
    "stocks_df = download_stock_data(tickers)\n",
    "\n",
    "stocks_df['Sharpe'] = (stocks_df['growth_252d'] - 1 - 0.045) / stocks_df['volatility']\n",
    "\n",
    "stocks_df['Date'] = pd.to_datetime(stocks_df['Date'])\n",
    "stocks_df_june6 = stocks_df[stocks_df['Date'] == '2025-06-06']\n",
    "\n",
    "stocks_df_june6 = stocks_df_june6[\n",
    "    stocks_df_june6['growth_252d'].notna() & \n",
    "    stocks_df_june6['Sharpe'].notna() & \n",
    "    (stocks_df_june6['Sharpe'] > 0) & \n",
    "    (stocks_df_june6['volatility'] < 0.5)\n",
    "]\n",
    "if len(stocks_df_june6) > 71:\n",
    "    stocks_df_june6 = stocks_df_june6.sort_values('Sharpe', ascending=False).head(71)\n",
    "elif len(stocks_df_june6) < 71:\n",
    "    stocks_df_june6 = stocks_df[stocks_df['Date'] == '2025-06-06']\n",
    "    stocks_df_june6 = stocks_df_june6[\n",
    "        stocks_df_june6['growth_252d'].notna() & \n",
    "        stocks_df_june6['Sharpe'].notna() & \n",
    "        (stocks_df_june6['volatility'] < 0.5)\n",
    "    ].sort_values('Sharpe', ascending=False).head(71)\n",
    "\n",
    "median_sharpe = stocks_df_june6['Sharpe'].median()\n",
    "print(f\"Median Sharpe Ratio for the 71 stocks: {median_sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f8632dc-231f-44a9-aaf3-60b660180805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  75 of 75 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of months to hold is 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "import yfinance as yf\n",
    "\n",
    "url = \"https://stockanalysis.com/ipos/2024/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "tables = pd.read_html(StringIO(response.text))\n",
    "df_ipos = tables[0]\n",
    "\n",
    "df_ipos['IPO Date'] = pd.to_datetime(df_ipos['IPO Date'])\n",
    "df_ipos = df_ipos[df_ipos['IPO Date'] < '2024-06-01']\n",
    "tickers = df_ipos['Symbol'].tolist()\n",
    "if len(tickers) > 75:\n",
    "    df_ipos = df_ipos.sort_values('IPO Date').head(75)\n",
    "    tickers = df_ipos['Symbol'].tolist()\n",
    "\n",
    "def download_stock_data(tickers, start_date='2024-01-01', end_date='2025-06-07'):\n",
    "    data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker', auto_adjust=False)\n",
    "    stocks_df = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        if ticker in data.columns.levels[0]:\n",
    "            ticker_data = data[ticker][['Close']].copy()\n",
    "            ticker_data = ticker_data.reset_index()\n",
    "            ticker_data['Ticker'] = ticker\n",
    "            ticker_data['Date'] = pd.to_datetime(ticker_data['Date'])\n",
    "            for months in range(1, 13):\n",
    "                days = months * 21\n",
    "                ticker_data[f'future_growth_{months}m'] = ticker_data['Close'].shift(-days) / ticker_data['Close']\n",
    "            stocks_df = pd.concat([stocks_df, ticker_data])\n",
    "    return stocks_df\n",
    "\n",
    "stocks_df = download_stock_data(tickers)\n",
    "\n",
    "min_date_df = stocks_df.groupby('Ticker')['Date'].min().reset_index()\n",
    "min_date_df = min_date_df.rename(columns={'Date': 'min_date'})\n",
    "\n",
    "result_df = pd.merge(\n",
    "    min_date_df,\n",
    "    stocks_df,\n",
    "    how='inner',\n",
    "    left_on=['Ticker', 'min_date'],\n",
    "    right_on=['Ticker', 'Date']\n",
    ")\n",
    "\n",
    "growth_columns = [f'future_growth_{m}m' for m in range(1, 13)]\n",
    "stats = result_df[growth_columns].describe()\n",
    "\n",
    "mean_growth = stats.loc['mean']\n",
    "optimal_month = mean_growth.idxmax()\n",
    "\n",
    "print(f\"The optimal number of months to hold is {int(optimal_month.split('_')[2][:-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0a1d00c-d15b-46d0-ae57-706d79dfc1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2025.4.26)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabrielf\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c5aa213-c3d6-4f42-8e02-026dddc5d0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1grCTCzMZKY5sJRtdbLVCXg8JXA8VPyg-\n",
      "From (redirected): https://drive.google.com/uc?id=1grCTCzMZKY5sJRtdbLVCXg8JXA8VPyg-&confirm=t&uuid=030aa77e-e575-439c-896f-af45bff9c140\n",
      "To: C:\\Users\\GabrielF\\data.parquet\n",
      "100%|██████████| 130M/130M [02:40<00:00, 809kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net income in $K: 24.30\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import pandas as pd\n",
    "\n",
    "file_id = \"1grCTCzMZKY5sJRtdbLVCXg8JXA8VPyg-\"\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"data.parquet\", quiet=False)\n",
    "df = pd.read_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "rsi_threshold = 25\n",
    "selected_df = df[\n",
    "    (df['rsi'] < rsi_threshold) &\n",
    "    (df['Date'] >= '2000-01-01') &\n",
    "    (df['Date'] <= '2025-06-01')\n",
    "]\n",
    "\n",
    "net_income = 1000 * (selected_df['growth_future_30d'] - 1).sum()\n",
    "net_income_thousands = net_income / 1000\n",
    "\n",
    "print(f\"Net income in $K: {net_income_thousands:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a347fc3-49a6-44f6-b0a1-a53d4bae14c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
