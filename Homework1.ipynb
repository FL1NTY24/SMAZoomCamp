{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc5ecdb-fdf3-419d-92d5-a83dc7e82b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year with the highest number of additions: 2017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "try:\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    tables = pd.read_html(url)\n",
    "    df = tables[0]\n",
    "\n",
    "    column_map = {\n",
    "        'Symbol': 'ticker',\n",
    "        'Security': 'name',\n",
    "        'Date added': 'date_added',\n",
    "        'Date first added': 'date_added'\n",
    "    }\n",
    "\n",
    "    available_columns = [col for col in column_map if col in df.columns]\n",
    "    if not available_columns:\n",
    "        raise ValueError(\"No expected columns found in the table\")\n",
    "\n",
    "    df = df[available_columns].rename(columns=column_map)\n",
    "\n",
    "    def extract_year(date):\n",
    "        if pd.isna(date):\n",
    "            return None\n",
    "        match = re.search(r'\\d{4}', str(date))\n",
    "        return int(match.group()) if match else None\n",
    "\n",
    "    if 'date_added' in df.columns:\n",
    "        df['year_added'] = df['date_added'].apply(extract_year)\n",
    "    else:\n",
    "        df['year_added'] = None\n",
    "\n",
    "    yearly_counts = df['year_added'].value_counts().sort_index()\n",
    "    yearly_counts = yearly_counts[yearly_counts.index != 1957]\n",
    "\n",
    "    if yearly_counts.empty:\n",
    "        raise ValueError(\"No valid years found after processing\")\n",
    "\n",
    "    max_count = yearly_counts.max()\n",
    "    max_years = yearly_counts[yearly_counts == max_count].index\n",
    "    most_recent_max_year = int(max_years.max())\n",
    "\n",
    "    print(f\"Year with the highest number of additions: {most_recent_max_year}\")\n",
    "\n",
    "    df.to_csv('sp500_companies.csv', index=False)\n",
    "    yearly_counts.to_csv('sp500_yearly_additions.csv', header=['count'])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496e8df-ad4c-422b-a0b1-566177d379fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65974fb4-6fba-4f16-aa96-7d83e12cdab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YTD Returns as of 2025-04-30:\n",
      "                    YTD Return (%)\n",
      "Ibovespa                 12.460354\n",
      "Hang Seng                12.152832\n",
      "DAX                      11.991065\n",
      "IPC Mexico               11.751647\n",
      "Nifty 50                  2.497794\n",
      "FTSE 100                  2.462445\n",
      "Shanghai Composite        0.738499\n",
      "S&P/TSX Composite        -0.094385\n",
      "S&P/ASX 200              -1.592451\n",
      "S&P 500                  -5.243539\n",
      "Nikkei 225               -8.820460\n",
      "\n",
      "Number of indexes with better YTD returns than S&P 500: 9\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "indices = {\n",
    "    'S&P 500': '^GSPC',\n",
    "    'Shanghai Composite': '000001.SS',\n",
    "    'Hang Seng': '^HSI',\n",
    "    'S&P/ASX 200': '^AXJO',\n",
    "    'Nifty 50': '^NSEI',\n",
    "    'S&P/TSX Composite': '^GSPTSE',\n",
    "    'DAX': '^GDAXI',\n",
    "    'FTSE 100': '^FTSE',\n",
    "    'Nikkei 225': '^N225',\n",
    "    'IPC Mexico': '^MXX',\n",
    "    'Ibovespa': '^BVSP'\n",
    "}\n",
    "\n",
    "start_date = '2025-01-01'\n",
    "end_date = '2025-04-30'\n",
    "\n",
    "returns = {}\n",
    "for name, ticker in indices.items():\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, auto_adjust=True, progress=False)\n",
    "    if not data.empty and 'Close' in data.columns:\n",
    "        close_data = data['Close'].dropna()\n",
    "        if len(close_data) >= 2:\n",
    "            start_price = close_data.iloc[0].item()\n",
    "            end_price = close_data.iloc[-1].item()\n",
    "            if isinstance(start_price, (int, float)) and isinstance(end_price, (int, float)):\n",
    "                ytd_return = ((end_price - start_price) / start_price) * 100\n",
    "                returns[name] = ytd_return\n",
    "    time.sleep(1)\n",
    "\n",
    "df = pd.DataFrame.from_dict(returns, orient='index', columns=['YTD Return (%)'])\n",
    "df = df.sort_values(by='YTD Return (%)', ascending=False)\n",
    "\n",
    "sp500_return = df.loc['S&P 500', 'YTD Return (%)']\n",
    "better_than_sp500 = len(df[df['YTD Return (%)'] > sp500_return])\n",
    "\n",
    "print(f\"YTD Returns as of {end_date}:\")\n",
    "print(df)\n",
    "print(f\"\\nNumber of indexes with better YTD returns than S&P 500: {better_than_sp500}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "705680cf-e5c8-4146-aeff-532c26914ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50th (median): 39\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "start_date = '1950-01-01'\n",
    "end_date = '2025-05-31'\n",
    "data = yf.download('^GSPC', start=start_date, end=end_date, auto_adjust=True, progress=False)\n",
    "\n",
    "prices = data['Close'].squeeze().dropna()\n",
    "\n",
    "all_time_highs = []\n",
    "max_price = -float('inf')\n",
    "for date, price in prices.items():\n",
    "    if isinstance(price, (int, float)) and not pd.isna(price):\n",
    "        if price > max_price:\n",
    "            all_time_highs.append((date, price))\n",
    "            max_price = price\n",
    "\n",
    "corrections = []\n",
    "for i in range(len(all_time_highs) - 1):\n",
    "    start_date, high_price = all_time_highs[i]\n",
    "    end_date, next_high = all_time_highs[i + 1]\n",
    "    \n",
    "    period_data = prices[(prices.index >= start_date) & (prices.index < end_date)]\n",
    "    if not period_data.empty:\n",
    "        min_price = period_data.min()\n",
    "        min_date = period_data.idxmin()\n",
    "        \n",
    "        if not pd.isna(min_price) and not pd.isna(min_date):\n",
    "            drawdown = (high_price - min_price) / high_price * 100\n",
    "            if drawdown >= 5:\n",
    "                duration = (min_date - start_date).days\n",
    "                if duration > 0:\n",
    "                    corrections.append({\n",
    "                        'start_date': start_date,\n",
    "                        'min_date': min_date,\n",
    "                        'high_price': high_price,\n",
    "                        'min_price': min_price,\n",
    "                        'drawdown': drawdown,\n",
    "                        'duration': duration\n",
    "                    })\n",
    "\n",
    "corrections_df = pd.DataFrame(corrections)\n",
    "median_duration = np.percentile(corrections_df['duration'], 50)\n",
    "print(f\"50th (median): {median_duration:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d4209df-25c7-49f9-a627-a3fa90633db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load earnings data\n",
    "csv_file = r\"C:\\Users\\GabrielF\\OneDrive - Freddy Hirsch Group (Pty) Ltd\\Desktop\\ha1_Amazon.csv\"\n",
    "earnings_df = pd.read_csv(csv_file, delimiter=';')\n",
    "\n",
    "# Parse Earnings Date\n",
    "earnings_df['Date'] = pd.to_datetime(earnings_df['Earnings Date'].str.split(' at ').str[0], errors='coerce')\n",
    "\n",
    "# Adjust for after-hours announcements (after 4 PM)\n",
    "earnings_df['Time'] = earnings_df['Earnings Date'].str.extract(r'at (\\d+:\\d+ [AP]M [A-Z]+)')\n",
    "earnings_df['Date'] = earnings_df.apply(\n",
    "    lambda row: row['Date'] + timedelta(days=1) if 'PM' in str(row['Time']) and int(row['Time'].split(':')[0]) >= 4 else row['Date'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Convert Surprise (%) to numeric\n",
    "earnings_df['Surprise (%)'] = pd.to_numeric(earnings_df['Surprise (%)'], errors='coerce')\n",
    "\n",
    "# Filter out future dates and invalid dates\n",
    "earnings_df = earnings_df[earnings_df['Date'] <= '2025-05-31'].dropna(subset=['Date'])\n",
    "\n",
    "# Identify positive earnings surprises (Surprise > 5%)\n",
    "positive_surprises = earnings_df[earnings_df['Surprise (%)'] > 5].copy()\n",
    "\n",
    "# Download AMZN price data\n",
    "ticker = 'AMZN'\n",
    "start_date = earnings_df['Date'].min() - timedelta(days=365)\n",
    "end_date = earnings_df['Date'].max() + timedelta(days=365)\n",
    "price_data = yf.download(ticker, start=start_date, end=end_date, auto_adjust=True, progress=False)\n",
    "prices = price_data['Close'].squeeze()\n",
    "\n",
    "# Calculate 2-day returns\n",
    "returns = []\n",
    "return_dates = []\n",
    "for i in range(2, len(prices)):\n",
    "    date1 = prices.index[i - 2]  # Day before reaction (Day 1)\n",
    "    date3 = prices.index[i]      # Two days after reaction (Day 3)\n",
    "    close1 = prices.iloc[i - 2]\n",
    "    close3 = prices.iloc[i]\n",
    "    if pd.isna(close1) or pd.isna(close3):\n",
    "        continue\n",
    "    two_day_return = (close3 / close1) - 1\n",
    "    returns.append(two_day_return * 100.0)\n",
    "    return_dates.append(prices.index[i - 1])  # Reaction day (Day 2)\n",
    "\n",
    "returns_df = pd.DataFrame({'Date': return_dates, '2_Day_Return': returns})\n",
    "returns_df['Date'] = pd.to_datetime(returns_df['Date'])\n",
    "\n",
    "# Merge with positive surprises\n",
    "merged_df = positive_surprises.merge(\n",
    "    returns_df,\n",
    "    how='left',\n",
    "    left_on='Date',\n",
    "    right_on='Date'\n",
    ")\n",
    "merged_df = merged_df.dropna(subset=['2_Day_Return'])\n",
    "\n",
    "# Calculate median\n",
    "median_positive = np.median(merged_df['2_Day_Return'])\n",
    "\n",
    "# Output\n",
    "print(f\"{median_positive:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1733bfe-c1ee-4ef5-a6fa-d967947f702e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
